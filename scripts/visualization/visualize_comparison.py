#!/usr/bin/env python3
"""
ä¸åŒå±‚æ•°å·ç§¯ç½‘ç»œçš„å¯è§†åŒ–å¯¹æ¯”
æ¯”è¾ƒ1å±‚Convã€2å±‚Convå’Œ3å±‚Convçš„æ¿€æ´»å¯è§†åŒ–
"""

import os
import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import matplotlib.animation as animation
from matplotlib.gridspec import GridSpec

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['PingFang SC', 'Hiragino Sans GB', 'STHeiti', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

from models.conv_comparison import get_model, get_model_info
from config import Config
from utils import set_seed
from data import DatasetLoader

class ComparisonVisualizer:
    """å¯¹æ¯”å¯è§†åŒ–å™¨"""
    
    def __init__(self):
        self.device = Config.DEVICE
        self.data_loader = DatasetLoader(
            dataset_name=Config.DATASET,
            data_dir=Config.DATA_DIR,
            batch_size=Config.BATCH_SIZE
        )
        self.train_loader, _ = self.data_loader.create_dataloaders()
        
    def load_trained_models(self, model_types=['conv1', 'conv2']):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        models = {}
        
        for model_type in model_types:
            checkpoint_path = f'./checkpoints/comparison/{model_type}_best.pth'
            
            if os.path.exists(checkpoint_path):
                # åŠ è½½æ¨¡å‹
                model = get_model(model_type, Config.INPUT_CHANNELS, Config.NUM_CLASSES)
                checkpoint = torch.load(checkpoint_path, map_location=self.device)
                model.load_state_dict(checkpoint['model_state_dict'])
                model = model.to(self.device)
                model.eval()
                
                models[model_type] = {
                    'model': model,
                    'accuracy': checkpoint['best_accuracy'],
                    'info': get_model_info(model_type)
                }
                
                print(f"âœ… åŠ è½½ {model_type} æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {checkpoint['best_accuracy']:.2f}%")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ° {model_type} æ¨¡å‹æ£€æŸ¥ç‚¹: {checkpoint_path}")
                # åˆ›å»ºæœªè®­ç»ƒçš„æ¨¡å‹ç”¨äºæ¼”ç¤º
                model = get_model(model_type, Config.INPUT_CHANNELS, Config.NUM_CLASSES)
                model = model.to(self.device)
                model.eval()
                
                models[model_type] = {
                    'model': model,
                    'accuracy': 0.0,
                    'info': get_model_info(model_type)
                }
                
                print(f"âš ï¸ ä½¿ç”¨æœªè®­ç»ƒçš„ {model_type} æ¨¡å‹è¿›è¡Œæ¼”ç¤º")
        
        return models
    
    def get_sample_data(self, target_digit=7, num_samples=4):
        """è·å–æ ·æœ¬æ•°æ®"""
        target_samples = []
        
        with torch.no_grad():
            for data, labels in self.train_loader:
                for i, label in enumerate(labels):
                    if label.item() == target_digit and len(target_samples) < num_samples:
                        target_samples.append(data[i])
                if len(target_samples) >= num_samples:
                    break
        
        print(f"âœ… æ”¶é›†åˆ° {len(target_samples)} ä¸ªæ•°å­— {target_digit} çš„æ ·æœ¬")
        return target_samples
    
    def visualize_activations_comparison(self, models, target_digit=7, num_samples=4, save_path=None):
        """å¯è§†åŒ–ä¸åŒæ¨¡å‹çš„æ¿€æ´»å¯¹æ¯”"""
        print(f"\nğŸ¨ å¯è§†åŒ–ä¸åŒæ¨¡å‹çš„æ¿€æ´»å¯¹æ¯” (æ•°å­— {target_digit})")
        print("=" * 60)
        
        # è·å–æ ·æœ¬æ•°æ®
        samples = self.get_sample_data(target_digit, num_samples)
        
        if not samples:
            print(f"âŒ æœªæ‰¾åˆ°æ•°å­— {target_digit} çš„æ ·æœ¬")
            return None
        
        # è·å–æ¯ä¸ªæ¨¡å‹çš„æ¿€æ´»
        all_activations = {}
        for model_type, model_data in models.items():
            model = model_data['model']
            activations = []
            
            with torch.no_grad():
                for sample in samples:
                    sample_batch = sample.unsqueeze(0).to(self.device)
                    acts = model.get_activations(sample_batch)
                    activations.append(acts)
            
            all_activations[model_type] = activations
            print(f"âœ… è·å– {model_type} æ¨¡å‹çš„æ¿€æ´»")
        
        # åˆ›å»ºå¯è§†åŒ–
        model_types = list(models.keys())
        num_models = len(model_types)
        
        fig = plt.figure(figsize=(20, 12))
        
        # ä¸ºæ¯ä¸ªæ ·æœ¬åˆ›å»ºä¸€è¡Œ
        for sample_idx in range(num_samples):
            sample = samples[sample_idx]
            
            # åŸå§‹å›¾åƒ
            ax_orig = plt.subplot2grid((num_samples + 1, num_models + 1), (sample_idx, 0))
            img = sample.squeeze().cpu().numpy()
            ax_orig.imshow(img, cmap='gray')
            ax_orig.set_title(f'Sample {sample_idx+1}\nDigit {target_digit}', fontsize=12)
            ax_orig.axis('off')
            
            # æ¯ä¸ªæ¨¡å‹çš„æ¿€æ´»
            for model_idx, model_type in enumerate(model_types):
                model_data = models[model_type]
                activations = all_activations[model_type][sample_idx]
                
                # è·å–è¯¥æ¨¡å‹çš„å·ç§¯å±‚
                conv_layers = model_data['info']['layers']
                
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªå·ç§¯å±‚çš„æ¿€æ´»
                if conv_layers and conv_layers[0] in activations:
                    ax = plt.subplot2grid((num_samples + 1, num_models + 1), (sample_idx, model_idx + 1))
                    conv_act = activations[conv_layers[0]].squeeze().detach().cpu().numpy()
                    
                    # å¦‚æœæ˜¯å¤šé€šé“ï¼Œè®¡ç®—å¹³å‡å€¼
                    if len(conv_act.shape) == 3:
                        conv_avg = conv_act.mean(axis=0)
                    else:
                        conv_avg = conv_act
                    
                    im = ax.imshow(conv_avg, cmap='hot')
                    ax.set_title(f'{model_data["info"]["name"]}\n{conv_layers[0]} (Acc: {model_data["accuracy"]:.1f}%)', 
                               fontsize=10)
                    ax.axis('off')
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯è¡Œ
        ax_stats = plt.subplot2grid((num_samples + 1, num_models + 1), (num_samples, 0), colspan=num_models + 1)
        ax_stats.axis('off')
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats_text = "æ¨¡å‹å¯¹æ¯”ç»Ÿè®¡:\n"
        for model_type, model_data in models.items():
            info = model_data['info']
            stats_text += f"{info['name']}: {info['params']}, å‡†ç¡®ç‡: {model_data['accuracy']:.2f}%\n"
        
        ax_stats.text(0.1, 0.5, stats_text, fontsize=12, verticalalignment='center',
                     bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))
        
        plt.suptitle(f'ä¸åŒå±‚æ•°å·ç§¯ç½‘ç»œæ¿€æ´»å¯¹æ¯” - æ•°å­— {target_digit}', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        if save_path is None:
            os.makedirs('./results', exist_ok=True)
            save_path = f'./results/conv_activations_comparison_{target_digit}.png'
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… æ¿€æ´»å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
        
        return fig
    
    def create_comparison_animation(self, models, target_digit=7, num_samples=4, save_path=None):
        """åˆ›å»ºå¯¹æ¯”åŠ¨ç”»"""
        print(f"\nğŸ¬ åˆ›å»ºä¸åŒæ¨¡å‹çš„å¯¹æ¯”åŠ¨ç”» (æ•°å­— {target_digit})")
        print("=" * 60)
        
        # è·å–æ ·æœ¬æ•°æ®
        samples = self.get_sample_data(target_digit, num_samples)
        
        if not samples:
            print(f"âŒ æœªæ‰¾åˆ°æ•°å­— {target_digit} çš„æ ·æœ¬")
            return None
        
        # è·å–æ¯ä¸ªæ¨¡å‹çš„æ¿€æ´»
        all_activations = {}
        for model_type, model_data in models.items():
            model = model_data['model']
            activations = []
            
            with torch.no_grad():
                for sample in samples:
                    sample_batch = sample.unsqueeze(0).to(self.device)
                    acts = model.get_activations(sample_batch)
                    activations.append(acts)
            
            all_activations[model_type] = activations
        
        # åˆ›å»ºåŠ¨ç”»
        model_types = list(models.keys())
        num_models = len(model_types)
        
        fig = plt.figure(figsize=(20, 12))
        
        def animate(frame):
            # æ¸…é™¤æ‰€æœ‰å­å›¾
            for ax in fig.axes:
                ax.clear()
            
            sample_idx = frame % num_samples
            sample = samples[sample_idx]
            
            # åŸå§‹å›¾åƒ
            ax_orig = plt.subplot2grid((num_samples + 1, num_models + 1), (0, 0))
            img = sample.squeeze().cpu().numpy()
            ax_orig.imshow(img, cmap='gray')
            ax_orig.set_title(f'Sample {sample_idx+1}\nDigit {target_digit}', fontsize=12)
            ax_orig.axis('off')
            
            # æ¯ä¸ªæ¨¡å‹çš„æ¿€æ´»
            for model_idx, model_type in enumerate(model_types):
                model_data = models[model_type]
                activations = all_activations[model_type][sample_idx]
                
                # è·å–è¯¥æ¨¡å‹çš„å·ç§¯å±‚
                conv_layers = model_data['info']['layers']
                
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªå·ç§¯å±‚çš„æ¿€æ´»
                if conv_layers and conv_layers[0] in activations:
                    ax = plt.subplot2grid((num_samples + 1, num_models + 1), (0, model_idx + 1))
                    conv_act = activations[conv_layers[0]].squeeze().detach().cpu().numpy()
                    
                    # å¦‚æœæ˜¯å¤šé€šé“ï¼Œè®¡ç®—å¹³å‡å€¼
                    if len(conv_act.shape) == 3:
                        conv_avg = conv_act.mean(axis=0)
                    else:
                        conv_avg = conv_act
                    
                    im = ax.imshow(conv_avg, cmap='hot')
                    ax.set_title(f'{model_data["info"]["name"]}\n{conv_layers[0]} (Acc: {model_data["accuracy"]:.1f}%)', 
                               fontsize=10)
                    ax.axis('off')
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            ax_stats = plt.subplot2grid((num_samples + 1, num_models + 1), (1, 0), colspan=num_models + 1)
            ax_stats.axis('off')
            
            # è®¡ç®—å½“å‰æ ·æœ¬çš„ç»Ÿè®¡ä¿¡æ¯
            stats_text = f"Sample {sample_idx + 1} æ¿€æ´»ç»Ÿè®¡:\n"
            for model_type, model_data in models.items():
                activations = all_activations[model_type][sample_idx]
                conv_layers = model_data['info']['layers']
                
                if conv_layers and conv_layers[0] in activations:
                    conv_act = activations[conv_layers[0]].squeeze().detach().cpu().numpy()
                    stats_text += f"{model_data['info']['name']}: mean={conv_act.mean():.3f}, std={conv_act.std():.3f}, max={conv_act.max():.3f}\n"
            
            ax_stats.text(0.1, 0.5, stats_text, fontsize=10, verticalalignment='center',
                         bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen", alpha=0.7))
        
        plt.suptitle(f'ä¸åŒå±‚æ•°å·ç§¯ç½‘ç»œæ¿€æ´»å¯¹æ¯”åŠ¨ç”» - æ•°å­— {target_digit}', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # åˆ›å»ºåŠ¨ç”»
        anim = animation.FuncAnimation(fig, animate, frames=num_samples * 3, 
                                     interval=1500, repeat=True)
        
        # ä¿å­˜åŠ¨ç”»
        if save_path is None:
            os.makedirs('./results', exist_ok=True)
            save_path = f'./results/conv_comparison_animation_{target_digit}.gif'
        
        print(f"ğŸ¬ æ­£åœ¨ç”Ÿæˆå¯¹æ¯”åŠ¨ç”»: {save_path}")
        
        try:
            anim.save(save_path, writer='pillow', fps=1)
            print(f"âœ… å¯¹æ¯”åŠ¨ç”»å·²ä¿å­˜åˆ°: {save_path}")
            
            # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
            file_size = os.path.getsize(save_path) / (1024 * 1024)  # MB
            print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            
        except Exception as e:
            print(f"âŒ åŠ¨ç”»ä¿å­˜å¤±è´¥: {e}")
            return None
        
        plt.show()
        
        return anim
    
    def visualize_detailed_channels_comparison(self, models, target_digit=7, save_path=None):
        """å¯è§†åŒ–è¯¦ç»†é€šé“å¯¹æ¯”"""
        print(f"\nğŸ” å¯è§†åŒ–è¯¦ç»†é€šé“å¯¹æ¯” (æ•°å­— {target_digit})")
        print("=" * 60)
        
        # è·å–ä¸€ä¸ªæ ·æœ¬
        samples = self.get_sample_data(target_digit, 1)
        if not samples:
            print(f"âŒ æœªæ‰¾åˆ°æ•°å­— {target_digit} çš„æ ·æœ¬")
            return None
        
        sample = samples[0]
        
        # è·å–æ¯ä¸ªæ¨¡å‹çš„æ¿€æ´»
        all_activations = {}
        for model_type, model_data in models.items():
            model = model_data['model']
            
            with torch.no_grad():
                sample_batch = sample.unsqueeze(0).to(self.device)
                acts = model.get_activations(sample_batch)
                all_activations[model_type] = acts
        
        # åˆ›å»ºå¯è§†åŒ–
        model_types = list(models.keys())
        num_models = len(model_types)
        
        fig = plt.figure(figsize=(24, 16))
        
        # åŸå§‹å›¾åƒ
        ax_orig = plt.subplot2grid((3, num_models + 1), (0, 0))
        img = sample.squeeze().cpu().numpy()
        ax_orig.imshow(img, cmap='gray')
        ax_orig.set_title(f'Original\nDigit {target_digit}', fontsize=12)
        ax_orig.axis('off')
        
        # æ¯ä¸ªæ¨¡å‹çš„è¯¦ç»†é€šé“
        for model_idx, model_type in enumerate(model_types):
            model_data = models[model_type]
            activations = all_activations[model_type]
            conv_layers = model_data['info']['layers']
            
            if conv_layers and conv_layers[0] in activations:
                conv_act = activations[conv_layers[0]].squeeze().detach().cpu().numpy()
                
                # æ˜¾ç¤ºæ‰€æœ‰é€šé“
                num_channels = conv_act.shape[0]
                cols = min(6, num_channels)  # æœ€å¤šæ˜¾ç¤º6åˆ—
                rows = (num_channels + cols - 1) // cols
                
                for ch_idx in range(num_channels):
                    row = ch_idx // cols
                    col = ch_idx % cols
                    
                    ax = plt.subplot2grid((3, num_models + 1), (row, model_idx + 1))
                    ax.imshow(conv_act[ch_idx], cmap='hot')
                    ax.set_title(f'{model_data["info"]["name"]}\nCh{ch_idx+1}', fontsize=8)
                    ax.axis('off')
        
        plt.suptitle(f'è¯¦ç»†é€šé“å¯¹æ¯” - æ•°å­— {target_digit}', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        if save_path is None:
            os.makedirs('./results', exist_ok=True)
            save_path = f'./results/detailed_channels_comparison_{target_digit}.png'
        
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… è¯¦ç»†é€šé“å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
        
        return fig

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¨ ä¸åŒå±‚æ•°å·ç§¯ç½‘ç»œå¯è§†åŒ–å¯¹æ¯”")
    print("=" * 80)
    
    # è®¾ç½®éšæœºç§å­
    set_seed(Config.RANDOM_SEED)
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = ComparisonVisualizer()
    
    try:
        # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        models = visualizer.load_trained_models(['conv1', 'conv2', 'conv3'])
        
        if not models:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
            return
        
        # å¯è§†åŒ–æ¿€æ´»å¯¹æ¯”
        visualizer.visualize_activations_comparison(models, target_digit=7, num_samples=4)
        
        # åˆ›å»ºå¯¹æ¯”åŠ¨ç”»
        visualizer.create_comparison_animation(models, target_digit=7, num_samples=4)
        
        # å¯è§†åŒ–è¯¦ç»†é€šé“å¯¹æ¯”
        visualizer.visualize_detailed_channels_comparison(models, target_digit=7)
        
        print("\nğŸ‰ å¯è§†åŒ–å¯¹æ¯”å®Œæˆ!")
        print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("- results/conv_activations_comparison_7.png")
        print("- results/conv_comparison_animation_7.gif")
        print("- results/detailed_channels_comparison_7.png")
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
