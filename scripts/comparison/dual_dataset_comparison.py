#!/usr/bin/env python3
"""
åŒæ•°æ®é›†å¯¹æ¯”åˆ†æè„šæœ¬
æµ‹è¯•3ä¸ªæ¨¡å‹ï¼ˆ1å±‚ã€2å±‚ã€3å±‚å·ç§¯ï¼‰åœ¨MNISTå’ŒCIFAR-10æ•°æ®é›†ä¸Šçš„æ€§èƒ½å·®å¼‚
"""

import os
import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import pandas as pd

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['PingFang SC', 'Hiragino Sans GB', 'STHeiti', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from models.adaptive_conv_comparison import get_adaptive_model, get_adaptive_model_info
from config import Config
from utils import set_seed
from data import DatasetLoader
from scripts.comparison.adaptive_train_comparison import AdaptiveComparisonTrainer

class DualDatasetComparison:
    """åŒæ•°æ®é›†å¯¹æ¯”åˆ†æå™¨"""
    
    def __init__(self):
        self.device = Config.DEVICE
        self.model_types = ['conv1', 'conv2', 'conv3']
        self.datasets = ['MNIST', 'CIFAR10']
        self.results = {}
        
    def run_comparison(self, epochs=3):
        """è¿è¡ŒåŒæ•°æ®é›†å¯¹æ¯”åˆ†æ"""
        print("ğŸ¯ åŒæ•°æ®é›†å·ç§¯å±‚æ•°å¯¹æ¯”åˆ†æ")
        print("=" * 80)
        print(f"ğŸ“Š æ•°æ®é›†: {', '.join(self.datasets)}")
        print(f"ğŸ—ï¸ æ¨¡å‹: {', '.join(self.model_types)}")
        print(f"ğŸ”„ è®­ç»ƒè½®æ•°: {epochs}")
        print("=" * 80)
        
        for dataset_name in self.datasets:
            print(f"\nğŸ“š æ•°æ®é›†: {dataset_name}")
            print("-" * 50)
            
            # æ›´æ–°é…ç½®
            original_dataset = Config.DATASET
            Config.DATASET = dataset_name
            
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            data_loader = DatasetLoader(
                dataset_name=dataset_name,
                data_dir=Config.DATA_DIR,
                batch_size=Config.BATCH_SIZE
            )
            train_loader, test_loader = data_loader.create_dataloaders()
            
            print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
            print(f"  è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")
            print(f"  æµ‹è¯•é›†å¤§å°: {len(test_loader.dataset)}")
            print(f"  æ‰¹æ¬¡å¤§å°: {Config.BATCH_SIZE}")
            print(f"  è®¾å¤‡: {Config.DEVICE}")
            
            # æ ¹æ®æ•°æ®é›†è®¾ç½®è¾“å…¥å‚æ•°
            input_channels = 3 if dataset_name == 'CIFAR10' else 1
            input_size = 32 if dataset_name == 'CIFAR10' else 28
            
            # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
            trainer = AdaptiveComparisonTrainer(
                model_types=self.model_types, 
                epochs=epochs,
                input_channels=input_channels,
                input_size=input_size
            )
            # æ›¿æ¢æ•°æ®åŠ è½½å™¨
            trainer.train_loader = train_loader
            trainer.test_loader = test_loader
            
            dataset_results = trainer.train_all_models()
            
            # å­˜å‚¨ç»“æœ
            self.results[dataset_name] = dataset_results
            
            # æ¢å¤åŸå§‹é…ç½®
            Config.DATASET = original_dataset
            
        # ç”Ÿæˆå¯¹æ¯”åˆ†æ
        self.generate_comparison_analysis()
        
    def generate_comparison_analysis(self):
        """ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Šå’Œå¯è§†åŒ–"""
        print("\nğŸ“Š ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š")
        print("-" * 50)
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs('results/dual_dataset_comparison', exist_ok=True)
        
        # 1. ç”Ÿæˆæ€§èƒ½å¯¹æ¯”è¡¨
        self.create_performance_table()
        
        # 2. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self.create_comparison_plots()
        
        # 3. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self.create_detailed_report()
        
    def create_performance_table(self):
        """åˆ›å»ºæ€§èƒ½å¯¹æ¯”è¡¨"""
        print("ğŸ“‹ åˆ›å»ºæ€§èƒ½å¯¹æ¯”è¡¨...")
        
        # å‡†å¤‡æ•°æ®
        data = []
        for dataset_name, dataset_results in self.results.items():
            for model_type, model_result in dataset_results.items():
                info = get_adaptive_model_info(model_type)
                data.append({
                    'æ•°æ®é›†': dataset_name,
                    'æ¨¡å‹': info['name'],
                    'å·ç§¯å±‚æ•°': len(info['conv_layers']),
                    'å‚æ•°é‡': info['params'],
                    'æµ‹è¯•å‡†ç¡®ç‡': f"{model_result['test_accuracy']:.2f}%",
                    'è®­ç»ƒå‡†ç¡®ç‡': f"{model_result['train_accuracy']:.2f}%",
                    'æœ€ä½³æµ‹è¯•æŸå¤±': f"{model_result['test_loss']:.4f}",
                    'è®­ç»ƒæ—¶é—´': f"{model_result.get('training_time', 0):.1f}s"
                })
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(data)
        
        # ä¿å­˜CSV
        csv_path = 'results/dual_dataset_comparison/performance_comparison.csv'
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… æ€§èƒ½å¯¹æ¯”è¡¨å·²ä¿å­˜åˆ°: {csv_path}")
        
        # æ‰“å°è¡¨æ ¼
        print("\nğŸ“Š æ€§èƒ½å¯¹æ¯”è¡¨:")
        print(df.to_string(index=False))
        
    def create_comparison_plots(self):
        """åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–å›¾è¡¨"""
        print("ğŸ“Š åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–å›¾è¡¨...")
        
        # 1. å‡†ç¡®ç‡å¯¹æ¯”å›¾
        self.plot_accuracy_comparison()
        
        # 2. å‚æ•°é‡vså‡†ç¡®ç‡å›¾
        self.plot_params_vs_accuracy()
        
        # 3. è®­ç»ƒæ›²çº¿å¯¹æ¯”
        self.plot_training_curves()
        
    def plot_accuracy_comparison(self):
        """ç»˜åˆ¶å‡†ç¡®ç‡å¯¹æ¯”å›¾"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # å‡†å¤‡æ•°æ®
        datasets = list(self.results.keys())
        model_types = self.model_types
        
        # MNISTå‡†ç¡®ç‡
        mnist_acc = [self.results['MNIST'][model]['test_accuracy'] for model in model_types]
        # CIFAR-10å‡†ç¡®ç‡
        cifar_acc = [self.results['CIFAR10'][model]['test_accuracy'] for model in model_types]
        
        x = np.arange(len(model_types))
        width = 0.35
        
        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        bars1 = ax1.bar(x - width/2, mnist_acc, width, label='MNIST', color='skyblue', alpha=0.8)
        bars2 = ax1.bar(x + width/2, cifar_acc, width, label='CIFAR-10', color='lightcoral', alpha=0.8)
        
        ax1.set_xlabel('æ¨¡å‹ç±»å‹')
        ax1.set_ylabel('æµ‹è¯•å‡†ç¡®ç‡ (%)')
        ax1.set_title('ä¸åŒæ¨¡å‹åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡å¯¹æ¯”')
        ax1.set_xticks(x)
        ax1.set_xticklabels([get_adaptive_model_info(model)['name'] for model in model_types], rotation=45)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars1:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{height:.1f}%', ha='center', va='bottom')
        for bar in bars2:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{height:.1f}%', ha='center', va='bottom')
        
        # å‡†ç¡®ç‡å·®å¼‚å›¾
        accuracy_diff = [cifar_acc[i] - mnist_acc[i] for i in range(len(model_types))]
        colors = ['red' if diff < 0 else 'green' for diff in accuracy_diff]
        
        bars3 = ax2.bar(x, accuracy_diff, color=colors, alpha=0.7)
        ax2.set_xlabel('æ¨¡å‹ç±»å‹')
        ax2.set_ylabel('å‡†ç¡®ç‡å·®å¼‚ (CIFAR-10 - MNIST)')
        ax2.set_title('CIFAR-10ä¸MNISTçš„å‡†ç¡®ç‡å·®å¼‚')
        ax2.set_xticks(x)
        ax2.set_xticklabels([get_adaptive_model_info(model)['name'] for model in model_types], rotation=45)
        ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)
        ax2.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars3:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + (0.5 if height > 0 else -0.5),
                    f'{height:.1f}%', ha='center', va='bottom' if height > 0 else 'top')
        
        plt.tight_layout()
        plt.savefig('results/dual_dataset_comparison/accuracy_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("âœ… å‡†ç¡®ç‡å¯¹æ¯”å›¾å·²ä¿å­˜")
        
    def plot_params_vs_accuracy(self):
        """ç»˜åˆ¶å‚æ•°é‡vså‡†ç¡®ç‡å›¾"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # MNISTæ•°æ®
        mnist_params = [get_adaptive_model_info(model)['params'] for model in self.model_types]
        mnist_acc = [self.results['MNIST'][model]['test_accuracy'] for model in self.model_types]
        
        # CIFAR-10æ•°æ®
        cifar_params = [get_adaptive_model_info(model)['params'] for model in self.model_types]
        cifar_acc = [self.results['CIFAR10'][model]['test_accuracy'] for model in self.model_types]
        
        # ç»˜åˆ¶æ•£ç‚¹å›¾
        ax1.scatter(mnist_params, mnist_acc, s=100, alpha=0.7, c='skyblue', edgecolors='navy')
        for i, model in enumerate(self.model_types):
            ax1.annotate(get_adaptive_model_info(model)['name'], 
                        (mnist_params[i], mnist_acc[i]), 
                        xytext=(5, 5), textcoords='offset points')
        
        ax1.set_xlabel('å‚æ•°é‡')
        ax1.set_ylabel('æµ‹è¯•å‡†ç¡®ç‡ (%)')
        ax1.set_title('MNIST: å‚æ•°é‡ vs å‡†ç¡®ç‡')
        ax1.grid(True, alpha=0.3)
        
        ax2.scatter(cifar_params, cifar_acc, s=100, alpha=0.7, c='lightcoral', edgecolors='darkred')
        for i, model in enumerate(self.model_types):
            ax2.annotate(get_adaptive_model_info(model)['name'], 
                        (cifar_params[i], cifar_acc[i]), 
                        xytext=(5, 5), textcoords='offset points')
        
        ax2.set_xlabel('å‚æ•°é‡')
        ax2.set_ylabel('æµ‹è¯•å‡†ç¡®ç‡ (%)')
        ax2.set_title('CIFAR-10: å‚æ•°é‡ vs å‡†ç¡®ç‡')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('results/dual_dataset_comparison/params_vs_accuracy.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("âœ… å‚æ•°é‡vså‡†ç¡®ç‡å›¾å·²ä¿å­˜")
        
    def plot_training_curves(self):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¯¹æ¯”"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        for i, model_type in enumerate(self.model_types):
            ax = axes[i]
            
            # ç»˜åˆ¶MNISTè®­ç»ƒæ›²çº¿
            if 'train_losses' in self.results['MNIST'][model_type]:
                epochs = range(1, len(self.results['MNIST'][model_type]['train_losses']) + 1)
                ax.plot(epochs, self.results['MNIST'][model_type]['train_losses'], 
                       'b-', label='MNIST è®­ç»ƒæŸå¤±', linewidth=2)
                ax.plot(epochs, self.results['MNIST'][model_type]['test_losses'], 
                       'b--', label='MNIST æµ‹è¯•æŸå¤±', linewidth=2)
            
            # ç»˜åˆ¶CIFAR-10è®­ç»ƒæ›²çº¿
            if 'train_losses' in self.results['CIFAR10'][model_type]:
                epochs = range(1, len(self.results['CIFAR10'][model_type]['train_losses']) + 1)
                ax.plot(epochs, self.results['CIFAR10'][model_type]['train_losses'], 
                       'r-', label='CIFAR-10 è®­ç»ƒæŸå¤±', linewidth=2)
                ax.plot(epochs, self.results['CIFAR10'][model_type]['test_losses'], 
                       'r--', label='CIFAR-10 æµ‹è¯•æŸå¤±', linewidth=2)
            
            ax.set_xlabel('è®­ç»ƒè½®æ•°')
            ax.set_ylabel('æŸå¤±å€¼')
            ax.set_title(f'{get_adaptive_model_info(model_type)["name"]} è®­ç»ƒæ›²çº¿')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('results/dual_dataset_comparison/training_curves.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("âœ… è®­ç»ƒæ›²çº¿å¯¹æ¯”å›¾å·²ä¿å­˜")
        
    def create_detailed_report(self):
        """åˆ›å»ºè¯¦ç»†åˆ†ææŠ¥å‘Š"""
        print("ğŸ“ åˆ›å»ºè¯¦ç»†åˆ†ææŠ¥å‘Š...")
        
        report_path = 'results/dual_dataset_comparison/dual_dataset_analysis_report.md'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# åŒæ•°æ®é›†å·ç§¯å±‚æ•°å¯¹æ¯”åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ğŸ“Š åˆ†ææ¦‚è¿°\n\n")
            f.write("æœ¬æŠ¥å‘Šå¯¹æ¯”äº†1å±‚ã€2å±‚ã€3å±‚å·ç§¯ç½‘ç»œåœ¨MNISTå’ŒCIFAR-10ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½å·®å¼‚ã€‚\n\n")
            
            f.write("## ğŸ—ï¸ æ¨¡å‹æ¶æ„\n\n")
            for model_type in self.model_types:
                info = get_adaptive_model_info(model_type)
                f.write(f"### {info['name']}\n")
                f.write(f"- **æè¿°**: {info['description']}\n")
                f.write(f"- **å‚æ•°é‡**: {info['params']}\n")
                f.write(f"- **å·ç§¯å±‚**: {', '.join(info['conv_layers'])}\n\n")
            
            f.write("## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”\n\n")
            f.write("### æµ‹è¯•å‡†ç¡®ç‡å¯¹æ¯”\n\n")
            f.write("| æ¨¡å‹ | MNISTå‡†ç¡®ç‡ | CIFAR-10å‡†ç¡®ç‡ | å·®å¼‚ |\n")
            f.write("|------|-------------|----------------|------|\n")
            
            for model_type in self.model_types:
                mnist_acc = self.results['MNIST'][model_type]['test_accuracy']
                cifar_acc = self.results['CIFAR10'][model_type]['test_accuracy']
                diff = cifar_acc - mnist_acc
                f.write(f"| {get_adaptive_model_info(model_type)['name']} | {mnist_acc:.2f}% | {cifar_acc:.2f}% | {diff:+.2f}% |\n")
            
            f.write("\n### å…³é”®å‘ç°\n\n")
            
            # åˆ†ææœ€ä½³æ€§èƒ½
            mnist_best = max(self.model_types, key=lambda x: self.results['MNIST'][x]['test_accuracy'])
            cifar_best = max(self.model_types, key=lambda x: self.results['CIFAR10'][x]['test_accuracy'])
            
            f.write(f"1. **MNISTæœ€ä½³æ¨¡å‹**: {get_adaptive_model_info(mnist_best)['name']} ({self.results['MNIST'][mnist_best]['test_accuracy']:.2f}%)\n")
            f.write(f"2. **CIFAR-10æœ€ä½³æ¨¡å‹**: {get_adaptive_model_info(cifar_best)['name']} ({self.results['CIFAR10'][cifar_best]['test_accuracy']:.2f}%)\n")
            
            # åˆ†æå‚æ•°é‡æ•ˆç‡
            f.write("\n### å‚æ•°é‡æ•ˆç‡åˆ†æ\n\n")
            f.write("| æ¨¡å‹ | å‚æ•°é‡ | MNISTæ•ˆç‡ | CIFAR-10æ•ˆç‡ |\n")
            f.write("|------|--------|-----------|--------------|\n")
            
            for model_type in self.model_types:
                params_str = get_adaptive_model_info(model_type)['params']
                # æå–å‚æ•°é‡æ•°å­—ï¼ˆå»æ‰"çº¦"å’Œ"Kå‚æ•°"ï¼‰
                if '152K' in params_str:
                    params = 152
                elif '62K' in params_str:
                    params = 62
                elif '34K' in params_str:
                    params = 34
                else:
                    params = 100  # é»˜è®¤å€¼
                
                mnist_eff = self.results['MNIST'][model_type]['test_accuracy'] / params
                cifar_eff = self.results['CIFAR10'][model_type]['test_accuracy'] / params
                f.write(f"| {get_adaptive_model_info(model_type)['name']} | {params_str} | {mnist_eff:.2f} | {cifar_eff:.2f} |\n")
            
            f.write("\n## ğŸ¯ ç»“è®ºä¸å»ºè®®\n\n")
            
            # ç”Ÿæˆç»“è®º
            f.write("### ä¸»è¦ç»“è®º\n\n")
            f.write("1. **æ•°æ®é›†å¤æ‚åº¦å½±å“**: CIFAR-10æ¯”MNISTæ›´å¤æ‚ï¼Œæ‰€æœ‰æ¨¡å‹çš„å‡†ç¡®ç‡éƒ½æ˜¾è‘—é™ä½\n")
            f.write("2. **æ¨¡å‹å¤æ‚åº¦æƒè¡¡**: æ›´æ·±çš„ç½‘ç»œåœ¨å¤æ‚æ•°æ®é›†ä¸Šè¡¨ç°æ›´å¥½ï¼Œä½†å‚æ•°é‡å¢åŠ \n")
            f.write("3. **æ•ˆç‡è€ƒè™‘**: éœ€è¦æ ¹æ®å…·ä½“åº”ç”¨åœºæ™¯å¹³è¡¡å‡†ç¡®ç‡å’Œè®¡ç®—èµ„æº\n\n")
            
            f.write("### åº”ç”¨å»ºè®®\n\n")
            f.write("- **MNIST**: 1å±‚å·ç§¯ç½‘ç»œå·²è¶³å¤Ÿï¼Œè®¡ç®—æ•ˆç‡é«˜\n")
            f.write("- **CIFAR-10**: å»ºè®®ä½¿ç”¨2-3å±‚å·ç§¯ç½‘ç»œä»¥è·å¾—æ›´å¥½æ€§èƒ½\n")
            f.write("- **èµ„æºå—é™**: ä¼˜å…ˆè€ƒè™‘1-2å±‚ç½‘ç»œ\n")
            f.write("- **æ€§èƒ½ä¼˜å…ˆ**: å¯é€‰æ‹©3å±‚ç½‘ç»œ\n\n")
            
            f.write("## ğŸ“ ç”Ÿæˆæ–‡ä»¶\n\n")
            f.write("- `performance_comparison.csv`: æ€§èƒ½å¯¹æ¯”è¡¨\n")
            f.write("- `accuracy_comparison.png`: å‡†ç¡®ç‡å¯¹æ¯”å›¾\n")
            f.write("- `params_vs_accuracy.png`: å‚æ•°é‡vså‡†ç¡®ç‡å›¾\n")
            f.write("- `training_curves.png`: è®­ç»ƒæ›²çº¿å¯¹æ¯”å›¾\n")
            f.write("- `dual_dataset_analysis_report.md`: æœ¬æŠ¥å‘Š\n\n")
        
        print(f"âœ… è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    set_seed(42)
    
    analyzer = DualDatasetComparison()
    analyzer.run_comparison(epochs=3)
    
    print("\nğŸ‰ åŒæ•°æ®é›†å¯¹æ¯”åˆ†æå®Œæˆ!")
    print("\nğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶:")
    print("- results/dual_dataset_comparison/ (æ‰€æœ‰ç»“æœæ–‡ä»¶)")

if __name__ == "__main__":
    main()
