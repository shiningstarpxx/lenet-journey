#!/usr/bin/env python3
"""
è‡ªé€‚åº”ä¸åŒå±‚æ•°å·ç§¯ç½‘ç»œçš„å¯¹æ¯”è®­ç»ƒè„šæœ¬
æ”¯æŒä¸åŒè¾“å…¥å°ºå¯¸å’Œé€šé“æ•°
"""

import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
import matplotlib.pyplot as plt
import matplotlib
import numpy as np

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['PingFang SC', 'Hiragino Sans GB', 'STHeiti', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from models.adaptive_conv_comparison import get_adaptive_model, get_adaptive_model_info
from config import Config
from utils import set_seed, load_checkpoint
from data import DatasetLoader

class AdaptiveComparisonTrainer:
    """è‡ªé€‚åº”å¯¹æ¯”è®­ç»ƒå™¨"""
    
    def __init__(self, model_types=['conv1', 'conv2', 'conv3'], epochs=5, input_channels=1, input_size=28):
        self.model_types = model_types
        self.epochs = epochs
        self.device = Config.DEVICE
        self.input_channels = input_channels
        self.input_size = input_size
        self.results = {}
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.data_loader = DatasetLoader(
            dataset_name=Config.DATASET,
            data_dir=Config.DATA_DIR,
            batch_size=Config.BATCH_SIZE
        )
        self.train_loader, self.test_loader = self.data_loader.create_dataloaders()
        
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"  è®­ç»ƒé›†å¤§å°: {len(self.train_loader.dataset)}")
        print(f"  æµ‹è¯•é›†å¤§å°: {len(self.test_loader.dataset)}")
        print(f"  æ‰¹æ¬¡å¤§å°: {Config.BATCH_SIZE}")
        print(f"  è®¾å¤‡: {self.device}")
        print(f"  è¾“å…¥é€šé“æ•°: {self.input_channels}")
        print(f"  è¾“å…¥å°ºå¯¸: {self.input_size}x{self.input_size}")
    
    def train_model(self, model_type):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {get_adaptive_model_info(model_type)['name']}")
        print("=" * 60)
        
        # åˆ›å»ºæ¨¡å‹
        model = get_adaptive_model(model_type, self.input_channels, Config.NUM_CLASSES, self.input_size)
        model = model.to(self.device)
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        optimizer = optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)
        criterion = nn.CrossEntropyLoss()
        
        # åˆ›å»ºTensorBoard writer
        log_dir = f'./logs/adaptive_comparison_{model_type}'
        writer = SummaryWriter(log_dir)
        
        # è®­ç»ƒå†å²
        train_losses = []
        train_accuracies = []
        test_losses = []
        test_accuracies = []
        
        best_accuracy = 0.0
        best_model_state = None
        
        for epoch in range(self.epochs):
            print(f"\nEpoch {epoch+1}/{self.epochs}")
            
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            train_correct = 0
            train_total = 0
            
            for batch_idx, (data, target) in enumerate(self.train_loader):
                data, target = data.to(self.device), target.to(self.device)
                
                optimizer.zero_grad()
                output = model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                _, predicted = torch.max(output.data, 1)
                train_total += target.size(0)
                train_correct += (predicted == target).sum().item()
                
                if batch_idx % 100 == 0:
                    print(f"  Batch {batch_idx}/{len(self.train_loader)}, Loss: {loss.item():.4f}, Acc: {100.*train_correct/train_total:.2f}%")
            
            # è®¡ç®—è®­ç»ƒå‡†ç¡®ç‡
            train_accuracy = 100. * train_correct / train_total
            avg_train_loss = train_loss / len(self.train_loader)
            
            # æµ‹è¯•é˜¶æ®µ
            model.eval()
            test_loss = 0.0
            test_correct = 0
            test_total = 0
            
            with torch.no_grad():
                for data, target in self.test_loader:
                    data, target = data.to(self.device), target.to(self.device)
                    output = model(data)
                    test_loss += criterion(output, target).item()
                    _, predicted = torch.max(output.data, 1)
                    test_total += target.size(0)
                    test_correct += (predicted == target).sum().item()
            
            # è®¡ç®—æµ‹è¯•å‡†ç¡®ç‡
            test_accuracy = 100. * test_correct / test_total
            avg_test_loss = test_loss / len(self.test_loader)
            
            print(f"  è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_accuracy:.2f}%")
            print(f"  æµ‹è¯•æŸå¤±: {avg_test_loss:.4f}, æµ‹è¯•å‡†ç¡®ç‡: {test_accuracy:.2f}%")
            
            # è®°å½•å†å²
            train_losses.append(avg_train_loss)
            train_accuracies.append(train_accuracy)
            test_losses.append(avg_test_loss)
            test_accuracies.append(test_accuracy)
            
            # è®°å½•åˆ°TensorBoard
            writer.add_scalar('Loss/Train', avg_train_loss, epoch)
            writer.add_scalar('Loss/Test', avg_test_loss, epoch)
            writer.add_scalar('Accuracy/Train', train_accuracy, epoch)
            writer.add_scalar('Accuracy/Test', test_accuracy, epoch)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if test_accuracy > best_accuracy:
                best_accuracy = test_accuracy
                best_model_state = model.state_dict().copy()
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        os.makedirs('./checkpoints/adaptive_comparison', exist_ok=True)
        model_path = f'./checkpoints/adaptive_comparison/{model_type}_best.pth'
        torch.save(best_model_state, model_path)
        
        print(f"\nâœ… {get_adaptive_model_info(model_type)['name']} è®­ç»ƒå®Œæˆ!")
        print(f"   æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡: {best_accuracy:.2f}%")
        print(f"   æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        
        # å…³é—­TensorBoard writer
        writer.close()
        
        # è¿”å›ç»“æœ
        return {
            'model_type': model_type,
            'best_accuracy': best_accuracy,
            'train_accuracy': train_accuracies[-1],
            'test_accuracy': test_accuracies[-1],
            'train_loss': train_losses[-1],
            'test_loss': test_losses[-1],
            'train_losses': train_losses,
            'test_losses': test_losses,
            'train_accuracies': train_accuracies,
            'test_accuracies': test_accuracies,
            'model_path': model_path
        }
    
    def train_all_models(self):
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        print("ğŸ¯ å¼€å§‹å¯¹æ¯”è®­ç»ƒä¸åŒå±‚æ•°çš„å·ç§¯ç½‘ç»œ")
        print("=" * 80)
        
        for model_type in self.model_types:
            info = get_adaptive_model_info(model_type)
            print(f"\nğŸ“‹ æ¨¡å‹ä¿¡æ¯:")
            print(f"   åç§°: {info['name']}")
            print(f"   æè¿°: {info['description']}")
            print(f"   å‚æ•°: {info['params']}")
            print(f"   å·ç§¯å±‚: {info['conv_layers']}")
            
            result = self.train_model(model_type)
            self.results[model_type] = result
        
        return self.results
    
    def plot_comparison(self):
        """ç»˜åˆ¶å¯¹æ¯”å›¾"""
        if not self.results:
            print("âŒ æ²¡æœ‰è®­ç»ƒç»“æœå¯ä»¥ç»˜åˆ¶")
            return
        
        print("\nğŸ“Š ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨...")
        
        # åˆ›å»ºå›¾è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        model_names = [get_adaptive_model_info(model_type)['name'] for model_type in self.model_types]
        accuracies = [self.results[model_type]['test_accuracy'] for model_type in self.model_types]
        train_accuracies = [self.results[model_type]['train_accuracy'] for model_type in self.model_types]
        
        # 1. æµ‹è¯•å‡†ç¡®ç‡å¯¹æ¯”
        bars1 = ax1.bar(model_names, accuracies, color=['skyblue', 'lightcoral', 'lightgreen'], alpha=0.8)
        ax1.set_title('æµ‹è¯•å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax1.set_ylabel('å‡†ç¡®ç‡ (%)')
        ax1.set_ylim(0, 100)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars1, accuracies):
            ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.5,
                    f'{acc:.2f}%', ha='center', va='bottom', fontweight='bold')
        
        # 2. è®­ç»ƒvsæµ‹è¯•å‡†ç¡®ç‡
        x = np.arange(len(model_names))
        width = 0.35
        
        bars2 = ax2.bar(x - width/2, train_accuracies, width, label='è®­ç»ƒå‡†ç¡®ç‡', color='lightblue', alpha=0.8)
        bars3 = ax2.bar(x + width/2, accuracies, width, label='æµ‹è¯•å‡†ç¡®ç‡', color='lightcoral', alpha=0.8)
        
        ax2.set_title('è®­ç»ƒvsæµ‹è¯•å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax2.set_ylabel('å‡†ç¡®ç‡ (%)')
        ax2.set_xticks(x)
        ax2.set_xticklabels(model_names, rotation=45)
        ax2.legend()
        ax2.set_ylim(0, 100)
        
        # 3. è®­ç»ƒæŸå¤±æ›²çº¿
        for model_type in self.model_types:
            train_losses = self.results[model_type]['train_losses']
            epochs = range(1, len(train_losses) + 1)
            ax3.plot(epochs, train_losses, marker='o', label=get_adaptive_model_info(model_type)['name'])
        
        ax3.set_title('è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
        ax3.set_xlabel('è®­ç»ƒè½®æ•°')
        ax3.set_ylabel('æŸå¤±å€¼')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. æµ‹è¯•å‡†ç¡®ç‡æ›²çº¿
        for model_type in self.model_types:
            test_accuracies = self.results[model_type]['test_accuracies']
            epochs = range(1, len(test_accuracies) + 1)
            ax4.plot(epochs, test_accuracies, marker='s', label=get_adaptive_model_info(model_type)['name'])
        
        ax4.set_title('æµ‹è¯•å‡†ç¡®ç‡æ›²çº¿', fontsize=14, fontweight='bold')
        ax4.set_xlabel('è®­ç»ƒè½®æ•°')
        ax4.set_ylabel('å‡†ç¡®ç‡ (%)')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        ax4.set_ylim(0, 100)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        os.makedirs('./results', exist_ok=True)
        plt.savefig('./results/adaptive_conv_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ… å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜åˆ°: ./results/adaptive_conv_comparison.png")

def main():
    """ä¸»å‡½æ•°"""
    set_seed(42)
    
    # æµ‹è¯•è‡ªé€‚åº”æ¨¡å‹
    print("ğŸ§ª æµ‹è¯•è‡ªé€‚åº”æ¨¡å‹...")
    trainer = AdaptiveComparisonTrainer(
        model_types=['conv1', 'conv2', 'conv3'], 
        epochs=3,
        input_channels=1,
        input_size=28
    )
    
    results = trainer.train_all_models()
    trainer.plot_comparison()
    
    print("\nğŸ‰ è‡ªé€‚åº”å¯¹æ¯”è®­ç»ƒå®Œæˆ!")
    print("\nğŸ“Š ç»“æœæ€»ç»“:")
    for model_type, result in results.items():
        print(f"  {get_adaptive_model_info(model_type)['name']}: {result['test_accuracy']:.2f}%")

if __name__ == "__main__":
    main()
