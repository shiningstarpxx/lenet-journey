#!/usr/bin/env python3
"""
æµ‹è¯•å¤šä¸ªæ•°å­—7çš„å¤šå±‚è¾“å‡ºç»“æœå±•ç¤º
ä¸“é—¨éªŒè¯è¿™ä¸ªåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec

from models import LeNet5
from config import Config
from utils import set_seed
from data import DatasetLoader

def test_multiple_7s_visualization():
    """æµ‹è¯•å¤šä¸ª7çš„å¤šå±‚è¾“å‡ºå¯è§†åŒ–"""
    print("ğŸ” æµ‹è¯•å¤šä¸ªæ•°å­—7çš„å¤šå±‚è¾“å‡ºå±•ç¤ºåŠŸèƒ½")
    print("=" * 60)
    
    # è®¾ç½®éšæœºç§å­
    set_seed(Config.RANDOM_SEED)
    
    # åˆ›å»ºæ¨¡å‹
    model = LeNet5(
        input_channels=Config.INPUT_CHANNELS,
        num_classes=Config.NUM_CLASSES
    )
    model.eval()
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    data_loader = DatasetLoader(
        dataset_name=Config.DATASET,
        data_dir=Config.DATA_DIR,
        batch_size=Config.BATCH_SIZE
    )
    train_loader, _ = data_loader.create_dataloaders()
    
    print("âœ… æ¨¡å‹å’Œæ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
    
    # æ”¶é›†æ•°å­—7çš„æ ·æœ¬
    target_digit = 7
    num_samples = 6
    target_samples = []
    target_labels = []
    
    print(f"ğŸ” æ”¶é›†æ•°å­— {target_digit} çš„æ ·æœ¬...")
    
    with torch.no_grad():
        for data, labels in train_loader:
            for i, label in enumerate(labels):
                if label.item() == target_digit and len(target_samples) < num_samples:
                    target_samples.append(data[i])
                    target_labels.append(label.item())
            
            if len(target_samples) >= num_samples:
                break
    
    print(f"âœ… æˆåŠŸæ”¶é›†åˆ° {len(target_samples)} ä¸ªæ•°å­— {target_digit} çš„æ ·æœ¬")
    
    if len(target_samples) == 0:
        print("âŒ æœªæ‰¾åˆ°ç›®æ ‡æ•°å­—çš„æ ·æœ¬")
        return False
    
    # è·å–å„å±‚æ¿€æ´»
    print("ğŸ” è·å–å„å±‚æ¿€æ´»...")
    activations = []
    
    with torch.no_grad():
        for i, sample in enumerate(target_samples):
            print(f"  å¤„ç†æ ·æœ¬ {i+1}/{len(target_samples)}")
            sample_batch = sample.unsqueeze(0).to(Config.DEVICE)
            
            if hasattr(model, 'get_activations'):
                acts = model.get_activations(sample_batch)
                activations.append(acts)
            else:
                print("âŒ æ¨¡å‹æ²¡æœ‰get_activationsæ–¹æ³•")
                return False
    
    print("âœ… æˆåŠŸè·å–æ‰€æœ‰æ ·æœ¬çš„æ¿€æ´»")
    
    # åˆ›å»ºå¯è§†åŒ–
    print("ğŸ¨ åˆ›å»ºå¤šå±‚è¾“å‡ºå¯è§†åŒ–...")
    
    # åˆ›å»ºå¤§å›¾
    fig = plt.figure(figsize=(24, 16))
    gs = GridSpec(4, num_samples, figure=fig)
    
    # å®šä¹‰å±‚åå’Œå¯¹åº”çš„ç½‘æ ¼ä½ç½®
    layers_info = [
        ('conv1', 0, 'Conv1 æ¿€æ´»\n(6é€šé“å¹³å‡)'),
        ('pool1', 1, 'Pool1 æ¿€æ´»\n(6é€šé“å¹³å‡)'),
        ('conv2', 2, 'Conv2 æ¿€æ´»\n(16é€šé“å¹³å‡)'),
        ('pool2', 3, 'Pool2 æ¿€æ´»\n(16é€šé“å¹³å‡)')
    ]
    
    for sample_idx, (sample, acts) in enumerate(zip(target_samples, activations)):
        print(f"  ç»˜åˆ¶æ ·æœ¬ {sample_idx + 1} çš„å¯è§†åŒ–...")
        
        # åŸå§‹å›¾åƒ
        ax_orig = fig.add_subplot(gs[0, sample_idx])
        img = sample.squeeze().cpu().numpy()
        ax_orig.imshow(img, cmap='gray')
        ax_orig.set_title(f'æ ·æœ¬ {sample_idx+1}\næ•°å­— {target_digit}', fontsize=10)
        ax_orig.axis('off')
        
        # å„å±‚æ¿€æ´»
        for layer_name, row, title in layers_info:
            if layer_name in acts:
                ax = fig.add_subplot(gs[row, sample_idx])
                act = acts[layer_name].squeeze().cpu().numpy()
                
                if len(act.shape) == 3:  # å·ç§¯å±‚
                    # æ˜¾ç¤ºæ‰€æœ‰é€šé“çš„å¹³å‡æ¿€æ´»
                    act_avg = act.mean(axis=0)
                    im = ax.imshow(act_avg, cmap='hot')
                    ax.set_title(title, fontsize=9)
                else:  # å…¶ä»–å±‚
                    # æ˜¾ç¤ºæ¿€æ´»å€¼çš„æ¡å½¢å›¾
                    ax.bar(range(len(act)), act, color='skyblue')
                    ax.set_title(title, fontsize=9)
                
                ax.axis('off')
    
    plt.suptitle(f'æ•°å­— {target_digit} çš„å¤šä¸ªæ ·æœ¬åœ¨å„å±‚çš„æ¿€æ´»æƒ…å†µ', fontsize=16)
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_path = os.path.join(Config.RESULTS_DIR, 'multiple_7s_layers_visualization.png')
    os.makedirs(Config.RESULTS_DIR, exist_ok=True)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š æ¿€æ´»ç»Ÿè®¡ä¿¡æ¯:")
    for sample_idx, acts in enumerate(activations):
        print(f"\næ ·æœ¬ {sample_idx + 1}:")
        for layer_name, _, _ in layers_info:
            if layer_name in acts:
                act = acts[layer_name].squeeze().cpu().numpy()
                if len(act.shape) == 3:
                    print(f"  {layer_name}: å½¢çŠ¶={act.shape}, å‡å€¼={act.mean():.4f}, æœ€å¤§å€¼={act.max():.4f}")
                else:
                    print(f"  {layer_name}: å½¢çŠ¶={act.shape}, å‡å€¼={act.mean():.4f}, æœ€å¤§å€¼={act.max():.4f}")
    
    return True

def test_detailed_conv_channels():
    """æµ‹è¯•è¯¦ç»†çš„å·ç§¯é€šé“å¯è§†åŒ–"""
    print("\nğŸ” æµ‹è¯•è¯¦ç»†çš„å·ç§¯é€šé“å¯è§†åŒ–")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡å‹
    model = LeNet5(
        input_channels=Config.INPUT_CHANNELS,
        num_classes=Config.NUM_CLASSES
    )
    model.eval()
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    data_loader = DatasetLoader(
        dataset_name=Config.DATASET,
        data_dir=Config.DATA_DIR,
        batch_size=Config.BATCH_SIZE
    )
    train_loader, _ = data_loader.create_dataloaders()
    
    # è·å–ä¸€ä¸ªæ•°å­—7çš„æ ·æœ¬
    target_digit = 7
    sample = None
    
    for data, labels in train_loader:
        for i, label in enumerate(labels):
            if label.item() == target_digit:
                sample = data[i]
                break
        if sample is not None:
            break
    
    if sample is None:
        print("âŒ æœªæ‰¾åˆ°æ•°å­—7çš„æ ·æœ¬")
        return False
    
    # è·å–æ¿€æ´»
    with torch.no_grad():
        sample_batch = sample.unsqueeze(0).to(Config.DEVICE)
        acts = model.get_activations(sample_batch)
    
    # åˆ›å»ºè¯¦ç»†å¯è§†åŒ–
    fig = plt.figure(figsize=(20, 12))
    
    # åŸå§‹å›¾åƒ
    ax_orig = plt.subplot2grid((3, 8), (0, 0), colspan=2)
    img = sample.squeeze().cpu().numpy()
    ax_orig.imshow(img, cmap='gray')
    ax_orig.set_title(f'åŸå§‹å›¾åƒ\næ•°å­— {target_digit}')
    ax_orig.axis('off')
    
    # Conv1 å„é€šé“
    conv1_act = acts['conv1'].squeeze().cpu().numpy()
    for i in range(6):
        ax = plt.subplot2grid((3, 8), (0, 2+i))
        ax.imshow(conv1_act[i], cmap='hot')
        ax.set_title(f'Conv1-{i+1}')
        ax.axis('off')
    
    # Conv2 å„é€šé“
    conv2_act = acts['conv2'].squeeze().cpu().numpy()
    for i in range(16):
        row = 1 + i // 8
        col = i % 8
        ax = plt.subplot2grid((3, 8), (row, col))
        ax.imshow(conv2_act[i], cmap='hot')
        ax.set_title(f'Conv2-{i+1}', fontsize=8)
        ax.axis('off')
    
    plt.suptitle(f'æ•°å­— {target_digit} çš„è¯¦ç»†å·ç§¯é€šé“æ¿€æ´»', fontsize=16)
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_path = os.path.join(Config.RESULTS_DIR, 'detailed_conv_channels_7.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… è¯¦ç»†é€šé“å¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª æµ‹è¯•å¤šä¸ªæ•°å­—7çš„å¤šå±‚è¾“å‡ºå±•ç¤ºåŠŸèƒ½")
    print("=" * 60)
    
    try:
        # æµ‹è¯•1: å¤šä¸ª7çš„å¤šå±‚è¾“å‡ºå±•ç¤º
        success1 = test_multiple_7s_visualization()
        
        if success1:
            print("\nâœ… æµ‹è¯•1é€šè¿‡: å¤šä¸ªæ•°å­—7çš„å¤šå±‚è¾“å‡ºå±•ç¤ºåŠŸèƒ½æ­£å¸¸")
        else:
            print("\nâŒ æµ‹è¯•1å¤±è´¥: å¤šä¸ªæ•°å­—7çš„å¤šå±‚è¾“å‡ºå±•ç¤ºåŠŸèƒ½å¼‚å¸¸")
        
        # æµ‹è¯•2: è¯¦ç»†çš„å·ç§¯é€šé“å¯è§†åŒ–
        success2 = test_detailed_conv_channels()
        
        if success2:
            print("\nâœ… æµ‹è¯•2é€šè¿‡: è¯¦ç»†å·ç§¯é€šé“å¯è§†åŒ–åŠŸèƒ½æ­£å¸¸")
        else:
            print("\nâŒ æµ‹è¯•2å¤±è´¥: è¯¦ç»†å·ç§¯é€šé“å¯è§†åŒ–åŠŸèƒ½å¼‚å¸¸")
        
        print("\n" + "=" * 60)
        if success1 and success2:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! å¤šä¸ª7çš„å¤šå±‚è¾“å‡ºå±•ç¤ºåŠŸèƒ½å®Œå…¨æ­£å¸¸")
            print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            print("- results/multiple_7s_layers_visualization.png")
            print("- results/detailed_conv_channels_7.png")
        else:
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
