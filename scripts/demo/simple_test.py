#!/usr/bin/env python3
"""
ç®€åŒ–çš„æµ‹è¯•è„šæœ¬ - ä¸“é—¨éªŒè¯å¤šä¸ª7çš„å¤šå±‚è¾“å‡ºå±•ç¤ºåŠŸèƒ½
"""

import os
import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib.gridspec import GridSpec

from models import LeNet5
from config import Config
from utils import set_seed
from data import DatasetLoader

def test_multiple_7s_simple():
    """ç®€åŒ–çš„å¤šä¸ª7æµ‹è¯•"""
    print("ğŸ” æµ‹è¯•å¤šä¸ªæ•°å­—7çš„å¤šå±‚è¾“å‡ºå±•ç¤ºåŠŸèƒ½")
    print("=" * 50)
    
    # è®¾ç½®éšæœºç§å­
    set_seed(Config.RANDOM_SEED)
    
    # åˆ›å»ºæ¨¡å‹
    model = LeNet5(input_channels=1, num_classes=10)
    model.eval()
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    data_loader = DatasetLoader(dataset_name='MNIST', data_dir='./data', batch_size=64)
    train_loader, _ = data_loader.create_dataloaders()
    
    # æ”¶é›†æ•°å­—7çš„æ ·æœ¬
    target_digit = 7
    num_samples = 4  # å‡å°‘æ ·æœ¬æ•°é‡ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•
    target_samples = []
    
    with torch.no_grad():
        for data, labels in train_loader:
            for i, label in enumerate(labels):
                if label.item() == target_digit and len(target_samples) < num_samples:
                    target_samples.append(data[i])
            if len(target_samples) >= num_samples:
                break
    
    print(f"âœ… æ”¶é›†åˆ° {len(target_samples)} ä¸ªæ•°å­— {target_digit} çš„æ ·æœ¬")
    
    # è·å–æ¿€æ´»
    activations = []
    with torch.no_grad():
        for sample in target_samples:
            sample_batch = sample.unsqueeze(0)
            acts = model.get_activations(sample_batch)
            activations.append(acts)
    
    print("âœ… æˆåŠŸè·å–æ‰€æœ‰æ ·æœ¬çš„æ¿€æ´»")
    
    # åˆ›å»ºå¯è§†åŒ–
    fig = plt.figure(figsize=(16, 12))
    gs = GridSpec(3, num_samples, figure=fig)
    
    for sample_idx, (sample, acts) in enumerate(zip(target_samples, activations)):
        # åŸå§‹å›¾åƒ
        ax_orig = fig.add_subplot(gs[0, sample_idx])
        img = sample.squeeze().numpy()
        ax_orig.imshow(img, cmap='gray')
        ax_orig.set_title(f'Sample {sample_idx+1}\nDigit {target_digit}')
        ax_orig.axis('off')
        
        # Conv1 æ¿€æ´»
        ax_conv1 = fig.add_subplot(gs[1, sample_idx])
        conv1_act = acts['conv1'].squeeze().detach().numpy()
        conv1_avg = conv1_act.mean(axis=0)
        ax_conv1.imshow(conv1_avg, cmap='hot')
        ax_conv1.set_title('Conv1 Activation\n(6 channels avg)')
        ax_conv1.axis('off')
        
        # Conv2 æ¿€æ´»
        ax_conv2 = fig.add_subplot(gs[2, sample_idx])
        conv2_act = acts['conv2'].squeeze().detach().numpy()
        conv2_avg = conv2_act.mean(axis=0)
        ax_conv2.imshow(conv2_avg, cmap='hot')
        ax_conv2.set_title('Conv2 Activation\n(16 channels avg)')
        ax_conv2.axis('off')
    
    plt.suptitle(f'Multiple Digit {target_digit} Samples - Layer Activations', fontsize=16)
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    os.makedirs('./results', exist_ok=True)
    save_path = './results/multiple_7s_simple_test.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š æ¿€æ´»ç»Ÿè®¡ä¿¡æ¯:")
    for sample_idx, acts in enumerate(activations):
        print(f"\nSample {sample_idx + 1}:")
        conv1_act = acts['conv1'].squeeze().detach().numpy()
        conv2_act = acts['conv2'].squeeze().detach().numpy()
        print(f"  Conv1: shape={conv1_act.shape}, mean={conv1_act.mean():.4f}, max={conv1_act.max():.4f}")
        print(f"  Conv2: shape={conv2_act.shape}, mean={conv2_act.mean():.4f}, max={conv2_act.max():.4f}")
    
    return True

def test_conv_channels_detailed():
    """æµ‹è¯•è¯¦ç»†çš„å·ç§¯é€šé“"""
    print("\nğŸ” æµ‹è¯•è¯¦ç»†çš„å·ç§¯é€šé“å¯è§†åŒ–")
    print("=" * 50)
    
    # åˆ›å»ºæ¨¡å‹
    model = LeNet5(input_channels=1, num_classes=10)
    model.eval()
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    data_loader = DatasetLoader(dataset_name='MNIST', data_dir='./data', batch_size=64)
    train_loader, _ = data_loader.create_dataloaders()
    
    # è·å–ä¸€ä¸ªæ•°å­—7çš„æ ·æœ¬
    target_digit = 7
    sample = None
    
    for data, labels in train_loader:
        for i, label in enumerate(labels):
            if label.item() == target_digit:
                sample = data[i]
                break
        if sample is not None:
            break
    
    if sample is None:
        print("âŒ æœªæ‰¾åˆ°æ•°å­—7çš„æ ·æœ¬")
        return False
    
    # è·å–æ¿€æ´»
    with torch.no_grad():
        sample_batch = sample.unsqueeze(0)
        acts = model.get_activations(sample_batch)
    
    # åˆ›å»ºè¯¦ç»†å¯è§†åŒ–
    fig = plt.figure(figsize=(20, 8))
    
    # åŸå§‹å›¾åƒ
    ax_orig = plt.subplot2grid((2, 8), (0, 0), colspan=2)
    img = sample.squeeze().numpy()
    ax_orig.imshow(img, cmap='gray')
    ax_orig.set_title(f'Original Image\nDigit {target_digit}')
    ax_orig.axis('off')
    
    # Conv1 å„é€šé“
    conv1_act = acts['conv1'].squeeze().detach().numpy()
    for i in range(6):
        ax = plt.subplot2grid((2, 8), (0, 2+i))
        ax.imshow(conv1_act[i], cmap='hot')
        ax.set_title(f'Conv1-{i+1}')
        ax.axis('off')
    
    # Conv2 å„é€šé“ (åªæ˜¾ç¤ºå‰8ä¸ª)
    conv2_act = acts['conv2'].squeeze().detach().numpy()
    for i in range(8):
        ax = plt.subplot2grid((2, 8), (1, i))
        ax.imshow(conv2_act[i], cmap='hot')
        ax.set_title(f'Conv2-{i+1}')
        ax.axis('off')
    
    plt.suptitle(f'Digit {target_digit} - Detailed Conv Channels', fontsize=16)
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_path = './results/detailed_conv_channels_simple.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… è¯¦ç»†é€šé“å¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}")
    
    plt.show()
    
    return True

def create_multiple_7s_animation():
    """åˆ›å»ºå¤šä¸ª7çš„å¤šå±‚è¾“å‡ºåŠ¨å›¾"""
    print("\nğŸ¬ åˆ›å»ºå¤šä¸ª7çš„å¤šå±‚è¾“å‡ºåŠ¨å›¾")
    print("=" * 50)
    
    # è®¾ç½®éšæœºç§å­
    set_seed(Config.RANDOM_SEED)
    
    # åˆ›å»ºæ¨¡å‹
    model = LeNet5(input_channels=1, num_classes=10)
    model.eval()
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    data_loader = DatasetLoader(dataset_name='MNIST', data_dir='./data', batch_size=64)
    train_loader, _ = data_loader.create_dataloaders()
    
    # æ”¶é›†æ•°å­—7çš„æ ·æœ¬
    target_digit = 7
    num_samples = 6
    target_samples = []
    
    with torch.no_grad():
        for data, labels in train_loader:
            for i, label in enumerate(labels):
                if label.item() == target_digit and len(target_samples) < num_samples:
                    target_samples.append(data[i])
            if len(target_samples) >= num_samples:
                break
    
    print(f"âœ… æ”¶é›†åˆ° {len(target_samples)} ä¸ªæ•°å­— {target_digit} çš„æ ·æœ¬")
    
    # è·å–æ¿€æ´»
    activations = []
    with torch.no_grad():
        for sample in target_samples:
            sample_batch = sample.unsqueeze(0)
            acts = model.get_activations(sample_batch)
            activations.append(acts)
    
    print("âœ… æˆåŠŸè·å–æ‰€æœ‰æ ·æœ¬çš„æ¿€æ´»")
    
    # åˆ›å»ºåŠ¨ç”»
    fig = plt.figure(figsize=(16, 10))
    gs = GridSpec(3, num_samples, figure=fig)
    
    def animate(frame):
        # æ¸…é™¤æ‰€æœ‰å­å›¾
        for ax in fig.axes:
            ax.clear()
        
        sample_idx = frame % num_samples
        sample = target_samples[sample_idx]
        acts = activations[sample_idx]
        
        # åŸå§‹å›¾åƒ
        ax_orig = fig.add_subplot(gs[0, sample_idx])
        img = sample.squeeze().numpy()
        ax_orig.imshow(img, cmap='gray')
        ax_orig.set_title(f'Sample {sample_idx+1}\nDigit {target_digit}')
        ax_orig.axis('off')
        
        # Conv1 æ¿€æ´»
        ax_conv1 = fig.add_subplot(gs[1, sample_idx])
        conv1_act = acts['conv1'].squeeze().detach().numpy()
        conv1_avg = conv1_act.mean(axis=0)
        ax_conv1.imshow(conv1_avg, cmap='hot')
        ax_conv1.set_title('Conv1 Activation\n(6 channels avg)')
        ax_conv1.axis('off')
        
        # Conv2 æ¿€æ´»
        ax_conv2 = fig.add_subplot(gs[2, sample_idx])
        conv2_act = acts['conv2'].squeeze().detach().numpy()
        conv2_avg = conv2_act.mean(axis=0)
        ax_conv2.imshow(conv2_avg, cmap='hot')
        ax_conv2.set_title('Conv2 Activation\n(16 channels avg)')
        ax_conv2.axis('off')
    
    plt.suptitle(f'Multiple Digit {target_digit} Samples - Layer Activations Animation', fontsize=16)
    plt.tight_layout()
    
    # åˆ›å»ºåŠ¨ç”»
    anim = animation.FuncAnimation(fig, animate, frames=num_samples*4, 
                                 interval=1000, repeat=True)
    
    # ä¿å­˜åŠ¨å›¾
    os.makedirs('./results', exist_ok=True)
    save_path = './results/multiple_7s_animation.gif'
    print(f"ğŸ¬ æ­£åœ¨ç”ŸæˆåŠ¨å›¾: {save_path}")
    
    try:
        anim.save(save_path, writer='pillow', fps=1)
        print(f"âœ… åŠ¨å›¾å·²ä¿å­˜åˆ°: {save_path}")
    except Exception as e:
        print(f"âŒ åŠ¨å›¾ä¿å­˜å¤±è´¥: {e}")
        return None
    
    plt.show()
    
    return anim

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª ç®€åŒ–æµ‹è¯• - å¤šä¸ªæ•°å­—7çš„å¤šå±‚è¾“å‡ºå±•ç¤ºåŠŸèƒ½")
    print("=" * 60)
    
    try:
        # æµ‹è¯•1: å¤šä¸ª7çš„å¤šå±‚è¾“å‡ºå±•ç¤º
        success1 = test_multiple_7s_simple()
        
        if success1:
            print("\nâœ… æµ‹è¯•1é€šè¿‡: å¤šä¸ªæ•°å­—7çš„å¤šå±‚è¾“å‡ºå±•ç¤ºåŠŸèƒ½æ­£å¸¸")
        else:
            print("\nâŒ æµ‹è¯•1å¤±è´¥")
        
        # æµ‹è¯•2: è¯¦ç»†çš„å·ç§¯é€šé“å¯è§†åŒ–
        success2 = test_conv_channels_detailed()
        
        if success2:
            print("\nâœ… æµ‹è¯•2é€šè¿‡: è¯¦ç»†å·ç§¯é€šé“å¯è§†åŒ–åŠŸèƒ½æ­£å¸¸")
        else:
            print("\nâŒ æµ‹è¯•2å¤±è´¥")
        
        # æµ‹è¯•3: ç”ŸæˆåŠ¨å›¾
        print("\nğŸ¬ å¼€å§‹ç”ŸæˆåŠ¨å›¾...")
        anim = create_multiple_7s_animation()
        
        if anim is not None:
            print("\nâœ… æµ‹è¯•3é€šè¿‡: åŠ¨å›¾ç”ŸæˆåŠŸèƒ½æ­£å¸¸")
            success3 = True
        else:
            print("\nâŒ æµ‹è¯•3å¤±è´¥: åŠ¨å›¾ç”Ÿæˆå¤±è´¥")
            success3 = False
        
        print("\n" + "=" * 60)
        if success1 and success2 and success3:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! å¤šä¸ª7çš„å¤šå±‚è¾“å‡ºå±•ç¤ºåŠŸèƒ½å®Œå…¨æ­£å¸¸")
            print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            print("- results/multiple_7s_simple_test.png")
            print("- results/detailed_conv_channels_simple.png")
            print("- results/multiple_7s_animation.gif")
        else:
            print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
